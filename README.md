# Inflation Prediction (1983â€“2023)
**Author:** Shreenath Gandhi  
**Tech Stack:** Python, Pandas, Scikit-learn, Seaborn, Matplotlib

## ğŸ¯ Objective
Can pre-crisis monetary and macroeconomic indicators (interest rates, GDP, unemployment) predict future U.S. inflation trends?

## ğŸ“Š Data Pipeline
- **Source:** Federal Reserve Economic Data (FRED)
- **Preprocessing:** 
  - Removed pre-1983 data for stability
  - Created synthetic target rate (post-2008 range midpoints)
  - Annualized GDP, unemployment, inflation
  - Engineered â€œDeviationâ€ between effective and target rates

## ğŸ§  Model
- Two **Random Forest regressors** trained on:
  - Positive drivers (Fed targets, GDP, etc.)
  - Negative drivers (unemployment, deviations)
- Ensemble weighted by RÂ² and inverse MSE
- Regime-based flags for tightening (+1) / easing (-1) cycles

## ğŸ“ˆ Results
- RÂ² â‰ˆ **0.63** on historical inflation (1983â€“2017)
- Directionally stable forecasts for 2018â€“2023
- Captures structural trends and regime shifts

## ğŸ§© Key Insights
- Inflation is highly sensitive to deviation between target and effective rates.
- Post-2008 monetary regimes behave differentlyâ€”captured by feature flags.
- Ensemble blending balances demand and supply-side effects.

## ğŸ“· Visuals
_(Insert your key plots here: historical fit + forecast chart)_

## ğŸ§® Tools
- pandas, numpy, matplotlib, seaborn
- scikit-learn (RandomForestRegressor, LOOCV)
- plotly (optional, for interactive visuals)

## Thought process and reasoning behind decisions
This project wasnâ€™t built in one pass. Below is the decision logâ€”what we tried, why we did it, what broke, and how we fixed it.

1) Data scope & stability
	â€¢	Decision: Start at 1983 and drop earlier rows.
Why: The early 80s are a volatile transition out of the high-inflation 70s. Starting in 1983 gives a more stable regime while preserving enough cycles for learning.
Pitfall avoided: Including pre-1983 amplified noise and regime breaks that hurt generalization.

2) Targets vs effective rate (policy mechanics)
	â€¢	Decision: Build a Synthetic Target Federal Funds Rate (SFFTR):
	â€¢	1983â€“2008: use the single Target Rate.
	â€¢	2008â€“2017: use the midpoint of the Target Range (avg of upper & lower).
Why: Post-2008 policy is expressed as a range. The midpoint is the most defensible single number.
Related feature: Deviation = Effective â€“ SyntheticTarget (signed), plus Deviation_abs during exploration.
	â€¢	What we learned: Targets matter because they encode policy stance, while Effective reflects market/operations. The gap (Deviation) adds information beyond either series alone.

3) Handling missing values
	â€¢	Decision:
	â€¢	Do not impute GDP/Inflation for modeling (we later either dropped or interpolated minimally and documented it).
	â€¢	Do not over-impute EFFR; for annual analysis we aggregate instead of filling every missing daily/monthly cell.
Why: We model at the annual level; filling sub-annual gaps creates false certainty and can bias aggregates.

4) Annual aggregation (fixing the â€œwild %â€ bug)
	â€¢	Initial mistake: We compounded values that were already annualized or duplicated across months, creating absurd results (e.g., GDP 35%, CPI 70%).
	â€¢	Fix:
	â€¢	If the source is already annualized (common for GDP growth and often for CPI YoY), use mean/median, not compounding.
	â€¢	If true sub-annual % changes, deduplicate to one value per period before compounding.
	â€¢	Added a safe aggregator that chooses mean for annualized series and product only for true sub-annual, de-duplicated changes.
Outcome: Realistic ranges: GDP ~ âˆ’3% to +7%, CPI ~ 1% to 5%, Unemployment ~ 4% to 10%.

5) Event diagnostics & interpretation
	â€¢	Observation: Large deviation spikes/dips around 1987 and 2008; other blips mid-90s and early-2000s.
	â€¢	Decision: Keep Deviation and Deviation_abs (during EDA) to see stress.
	â€¢	Interpretation: Not all big deviations = â€œcrisis.â€ In 2008â€“09, policy cut rates to zero (small deviation but extreme context).
	â€¢	Conclusion: Do not redefine â€œcrisisâ€ by deviation magnitude alone; treat deviation as a continuous signal and crisis as a context flag.

6) Crisis flags: static vs dynamic
	â€¢	Initial idea: Dynamic is_crisis from deviation spikes.
	â€¢	Decision: Keep is_crisis static (e.g., 1987â€“88, 2001â€“02, 2008â€“09).
Why: Preserves interpretability and consistency across analyses.
	â€¢	Refinement: Add regime3 (âˆ’1 easing crisis, 0 normal, +1 tightening crisis) using crisis flag and deviation sign (â‰¤ small negative threshold â†’ easing).
Benefit: Encodes direction of policy stress without moving the goalposts.

7) Final feature set (annual, interpretable)
	â€¢	Core columns: Year, Synthetic_Target_Rate, Deviation, Real GDP (Percent Change), Unemployment Rate, Inflation Rate.
	â€¢	Context flags: is_post_2008, is_crisis, and regime3 (âˆ’1/0/+1).
	â€¢	Rationale: Compact, macro-intuitive set that captures stance (target), slippage (deviation), real activity (GDP), slack (unemployment), and regime.

8) Modeling strategy (small-sample, interpretable)
	â€¢	Baseline: Linear models for sanity checks.
	â€¢	Final approach: Directional Ensemble (â€œpositive vs negative driversâ€):
	â€¢	Positive model (forest): Synthetic_Target_Rate, Real GDP, Deviation, is_post_2008, regime3.
	â€¢	Negative model (forest): Unemployment, Deviation, is_post_2008, regime3.
	â€¢	Ensemble weights: RÂ² and inverse MSE from LOOCV (out-of-fold).
Why: Mirrors macro logic (inflationary vs disinflationary forces) while staying data-driven.
	â€¢	LOOCV: Chosen due to ~35 annual samples. Uses nearly all data while measuring generalization per point.

9) Things we tried that didnâ€™t move much (and why)
	â€¢	Time-weighted training (RF): Sample weights had limited effectâ€”RF splits were similar under smooth Great-Moderation dynamics; ensemble dominated by the positive model.
	â€¢	GBRT / HistGBR: Considered for stronger response to weights; required NaN handling (we used HistGBR for NaN tolerance). Kept RF for clarity and stability in the final repo.
	â€¢	Dynamic crisis from deviation magnitude: Conceptually neat, but confused semantics; we kept crisis static and used deviation separately.

10) Post-2017 forecasting & limitations
	â€¢	GDP & Inflation forecasts (2018â€“2023): We used the trained structure to project out-of-sample.
	â€¢	Reality check: The model misses COVID-era extremes (2020â€“2021) because no such shock exists in training (1983â€“2017).
	â€¢	Mitigation: Mark pandemic years as is_crisis=1 and set regime3 (easing). Still, structural breaks remain hard without new features (e.g., Fed balance sheet %, supply-chain stress, energy shocks).
	â€¢	Honest positioning: Forecasts are directional/structural, not point-perfect during shocks.

11) Reproducibility & repo hygiene
	â€¢	Kept a minimal requirements.txt (pandas/numpy/sklearn/matplotlib/seaborn/statsmodels/plotly).
	â€¢	Separated notebooks:
	â€¢	Data Preparation (cleaning, aggregation, features)
	â€¢	Prediction (modeling, LOOCV, plots)
	â€¢	Saved final dataset for quick starts and review.

â¸»

Key takeaways
	â€¢	Donâ€™t compound whatâ€™s already annualized (fixes wild % errors).
	â€¢	Model stance, slippage, and regime: target rate, deviation, and flags jointly matter.
	â€¢	Directional ensemble is a practical way to encode macro intuition: expansionary vs contractionary forces.
	â€¢	Be explicit about limitations around structural breaks (COVID/2008-style shocks).

This transparent decision trail is the backbone of the projectâ€™s credibilityâ€”and why the final model is both explainable and reproducible.
